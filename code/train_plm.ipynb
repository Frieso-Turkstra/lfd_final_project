{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yKB6eTK0sd9b"
      },
      "source": [
        "Mount your google drive folder"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wMO9y0Vzmz6J"
      },
      "outputs": [],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WjWxqb2qstLA"
      },
      "source": [
        "Install transformer library"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IHgcJRpl2Ub6"
      },
      "outputs": [],
      "source": [
        "%%capture\n",
        "!pip install transformers"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uL2c7DgnXec-"
      },
      "source": [
        "Log into HuggingFace for uploading the fine-tuned model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "aJ7Drb0YXeoi"
      },
      "outputs": [],
      "source": [
        "# !huggingface-cli login"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_qMnliw2tK9D"
      },
      "source": [
        "Import libraries and packages needed for this notebook and set random seeds (this will not make the experiment fully reproducible)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bwtZ4JN6rbER"
      },
      "outputs": [],
      "source": [
        "import random\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "import matplotlib.pyplot as plt\n",
        "import pandas as pd\n",
        "from transformers import set_seed, TFAutoModelForSequenceClassification, AutoTokenizer\n",
        "from tensorflow.keras.losses import CategoricalCrossentropy, BinaryCrossentropy\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from sklearn.preprocessing import LabelBinarizer\n",
        "from sklearn.metrics import classification_report, confusion_matrix, ConfusionMatrixDisplay, f1_score\n",
        "from sklearn.utils import class_weight\n",
        "\n",
        "seed = 101\n",
        "random.seed(seed)\n",
        "np.random.seed(seed)\n",
        "tf.random.set_seed(seed)\n",
        "set_seed(seed)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ij2c-0O8uDlV"
      },
      "source": [
        "Read in train, dev and test files"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TCNe6HFPH1FV"
      },
      "outputs": [],
      "source": [
        "def read_corpus(corpus_file):\n",
        "    '''Reads a string and returns a list of words and a list of corresponding labels.'''\n",
        "    documents = []\n",
        "    labels = []\n",
        "\n",
        "    with open(corpus_file, encoding='utf-8') as in_file:\n",
        "        for line in in_file:\n",
        "            tokens = line.strip().split('\\t')\n",
        "            documents.append(tokens[0])\n",
        "            labels.append(tokens[1])\n",
        "\n",
        "    return documents, labels\n",
        "\n",
        "# Path to project folder\n",
        "path = \"/content/gdrive/MyDrive/LFD_FP/\"\n",
        "\n",
        "# Telegram data\n",
        "# X_train, Y_train = read_corpus(path + \"data/telegram/train.tsv\")\n",
        "# X_dev, Y_dev = read_corpus(path + \"data/telegram/dev.tsv\")\n",
        "\n",
        "# Twitter data\n",
        "X_train, Y_train = read_corpus(path + \"data/twitter/train.tsv\")\n",
        "X_dev, Y_dev = read_corpus(path + \"data/twitter/dev.tsv\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NEnoULfPuGRm"
      },
      "source": [
        "Load in model and tokenizer from Huggingface"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6LB-9UJmjANO"
      },
      "outputs": [],
      "source": [
        "# lm = \"bert-base-cased\"\n",
        "# lm = \"bert-base-uncased\"\n",
        "# lm = \"distilbert-base-cased\"\n",
        "# lm = \"distilbert-base-uncased\"\n",
        "lm = \"roberta-base\"\n",
        "# lm = \"albert-base-v2\"\n",
        "tokenizer = AutoTokenizer.from_pretrained(lm)\n",
        "model = TFAutoModelForSequenceClassification.from_pretrained(lm, num_labels=1)\n",
        "max_length = 300\n",
        "\n",
        "tokens_train = tokenizer(X_train, padding=True, max_length=max_length,\n",
        "truncation=True, return_tensors=\"np\").data\n",
        "tokens_dev = tokenizer(X_dev, padding=True, max_length=max_length,\n",
        "truncation=True, return_tensors=\"np\").data\n",
        "tokens_test = tokenizer(X_test, padding=True, max_length=max_length,\n",
        "truncation=True, return_tensors=\"np\").data"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Bpte5Ke5ueHw"
      },
      "source": [
        "Set loss function, learning rate or learning rate scheduler and optimizer"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "POLGZIyCkonI"
      },
      "outputs": [],
      "source": [
        "loss_function = BinaryCrossentropy(from_logits=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2gOqxHoFnMnT"
      },
      "outputs": [],
      "source": [
        "initial_learning_rate = 3e-5\n",
        "lr_schedule = tf.keras.optimizers.schedules.PolynomialDecay(\n",
        "    initial_learning_rate,\n",
        "    decay_steps=1000,\n",
        "    end_learning_rate=1e-7,\n",
        "    power=0.5,\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VQG-SFlpks24"
      },
      "outputs": [],
      "source": [
        "optim = Adam(learning_rate=lr_schedule)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_CNreAYEum5c"
      },
      "source": [
        "Transform string labels to one-hot encodings"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fu_v7xYak7C-"
      },
      "outputs": [],
      "source": [
        "encoder = LabelBinarizer()\n",
        "Y_train_bin = encoder.fit_transform(Y_train)\n",
        "Y_dev_bin = encoder.fit_transform(Y_dev)\n",
        "Y_test_bin = encoder.fit_transform(Y_test)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JDQIbd4M6mYW"
      },
      "source": [
        "Calculate class weights"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1oTJrl4vs_Rx"
      },
      "outputs": [],
      "source": [
        "weights = class_weight.compute_class_weight(class_weight='balanced', classes=np.unique(Y_train), y=Y_train)\n",
        "weights_dict = {i: weight for i, weight in enumerate(weights)}"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "P_nXwUM0uwPC"
      },
      "source": [
        "Compile and fit the model using an early stopping callback"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OAsyv8i3kxYb"
      },
      "outputs": [],
      "source": [
        "batch_size = 16\n",
        "callback = tf.keras.callbacks.EarlyStopping(monitor='val_loss', patience=3, restore_best_weights=True)\n",
        "model.compile(loss=loss_function, optimizer=optim, metrics=['accuracy'])\n",
        "# To use class weights, make sure the parameter class_weight=weights_dict is set\n",
        "model.fit(tokens_train, Y_train_bin, verbose=1, epochs=5, callbacks=[callback],\n",
        "batch_size=batch_size, validation_data=(tokens_dev, Y_dev_bin), class_weight=weights_dict)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-YU3WpyYu6Q-"
      },
      "source": [
        "Print loss and accuracy on the dev set"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iz9pusEnmHOR"
      },
      "outputs": [],
      "source": [
        "results = model.evaluate(tokens_dev, Y_dev_bin, batch_size=batch_size)\n",
        "print(results)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YnHC36PLvn4W"
      },
      "source": [
        "Print classification report and confusion matrix on the test set"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OAO3I0ZgRpxv"
      },
      "outputs": [],
      "source": [
        "def print_measures(Y_test, Y_pred, plot_cm=False):\n",
        "    ''' Takes in true labels Y_test, predicted labels Y_pred and a boolean\n",
        "    plot_cm (default=False). Prints a classification report (precision, recall\n",
        "    and F1 score for each class) and a confusion matrix with labels. To plot a\n",
        "    visualization of the confusion matrix, set plot_cm to True'''\n",
        "    report = classification_report(Y_test, Y_pred, digits=3)\n",
        "\n",
        "    # Create a confusion matrix with labels\n",
        "    labels = np.unique(Y_test)\n",
        "    cm = confusion_matrix(Y_test, Y_pred, labels=labels)\n",
        "    cm_labeled = pd.DataFrame(cm, index=labels, columns=labels)\n",
        "\n",
        "    print(\"Classification report:\\n\\n\", report)\n",
        "    print(\"Confusion matrix:\\n\\n\", cm_labeled)\n",
        "\n",
        "    if plot_cm:\n",
        "      # Plot confusion matrix using pyplot\n",
        "        display = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=labels)\n",
        "        display.plot()\n",
        "        plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "w4DgFKC_OfJo"
      },
      "outputs": [],
      "source": [
        "predictions = model.predict(tokens_dev)['logits']\n",
        "Y_pred = encoder.inverse_transform(predictions)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tGEu33FPOxBO"
      },
      "outputs": [],
      "source": [
        "print_measures(Y_dev, Y_pred, plot_cm=False)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iEClgj2EYPIw"
      },
      "source": [
        "Push model to HuggingFace"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tndEFtxUYOYc"
      },
      "outputs": [],
      "source": [
        "# model.push_to_hub(\"roberta-offense-telegram\")\n",
        "# model.push_to_hub(\"roberta-offense-twitter\")"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "V100",
      "machine_shape": "hm",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
